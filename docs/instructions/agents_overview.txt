# Agent Implementation Overview - Chatbot RAG Project
# Last updated: May 2023

## Project Overview

This project implements a RAG (Retrieval-Augmented Generation) chatbot that answers questions based on lecture transcripts. The system allows users to select a specific lecture and ask questions about its content, with the chatbot providing answers based on the retrieved lecture transcription.

Key components:
- **Agent Architecture**: Implements context-based prompt creation and response generation
- **Backend**: Python-based service with CLI interface for interactive conversations
- **API Integration**: Uses OpenRouter for LLM (Large Language Model) access 
- **Data Source**: Retrieves transcription data from Supabase database

## Agent Architecture

The chatbot agent follows a simple yet effective architecture:

### Core Components:
1. **Context Integration**: Combines lecture transcription with user questions
2. **Prompt Engineering**: Creates effectively structured prompts for the LLM
3. **Conversation Management**: Maintains history of questions and answers
4. **API Integration**: Handles communication with OpenRouter/OpenAI

### Main Classes and Functions:

#### ChatbotAgent Class
The central component that handles all agent functionality:
```python
class ChatbotAgent:
    def __init__(self, api_key=None):
        # Initialize with OpenRouter API key
        # Set up OpenAI client with OpenRouter base URL
        # Initialize conversation history

    def create_prompt_with_context(self, question, transcription, lesson_info):
        # Create system message with instructions and lesson metadata
        # Add context message with transcription
        # Incorporate conversation history
        # Add the current question
        # Return structured messages array for the LLM

    def process_question(self, question, transcription, lesson_info, model="openai/gpt-4o"):
        # Create prompt with context
        # Call the LLM via OpenRouter
        # Extract and return the response
        # Update conversation history

    def reset_conversation(self):
        # Clear conversation history
```

## Prompt Engineering

The agent uses a carefully designed prompt structure:

1. **System Message**: Defines the assistant's role, providing instructions on how to answer and including metadata about the lecture.

2. **Context Message**: Contains the full lecture transcription to provide the knowledge base for answering questions.

3. **Conversation History**: Includes previous questions and answers for context continuity.

4. **Current Question**: The user's current query to be answered.

Example prompt structure:
```
[System Message]
You are an educational assistant that helps answer questions about lectures.
You have access to the transcription of a specific lecture, and you should use this information to provide accurate answers.
If the answer cannot be found in the transcription, acknowledge that and provide the most helpful response you can.

Lecture Information:
- Title: {lesson_title}
- Module: {module_name}
- Course: {course_name}
- Area: {area}
- Type: {type}

[Context Message]
Here is the transcription of the lecture:
{full_transcription}
Please help me answer questions about this lecture.

[Previous Questions and Answers, if any]

[Current Question]
{user_question}
```

## Integration with Database

The agent integrates with the database service to retrieve lecture transcriptions:

1. **Lesson Selection**: Retrieves a list of available lessons from Supabase
2. **Transcription Retrieval**: Fetches the specific lecture transcription by lesson ID
3. **Metadata Access**: Obtains related lesson and course information for context

The database service provides formatted data with the following structure:
```python
{
    "transcription": "Full lecture text...",
    "video_summary": "Brief summary of the video content",
    "aula_nome": "Lesson name",
    "modulo": "Module name",
    "courses": {
        "curso_nome": "Course name",
        "pilar": "Knowledge area",
        "tipo": "Course type"
    }
}
```

## Command-Line Interface

The project includes a CLI for interacting with the chatbot:

### Features:
- Lesson browsing and selection
- Interactive question-answering session
- Conversation history management
- Model selection options

### CLI Components:
1. **Lesson Display**: Lists available lessons with ID, course, module, and name
2. **Lesson Selection**: Allows users to select a lesson by ID
3. **Interactive Chat**: Provides a prompt-based interface for asking questions
4. **History Management**: Supports resetting conversation history

Usage:
```
# Start interactive session
python backend/python_modules/chatbot_cli.py

# Query a specific lesson directly
python backend/python_modules/chatbot_cli.py --lesson-id <lesson_id>

# Use a different model
python backend/python_modules/chatbot_cli.py --model "anthropic/claude-3-haiku-20240307"
```

## Testing and Validation

The project includes comprehensive testing tools:

1. **Unit Tests**: Tests for core agent functions (`test_agent.py`)
   - Prompt creation validation
   - Question processing verification
   - Response generation testing

2. **Integration Tests**: End-to-end functionality testing (`main.py`)
   - Database connectivity
   - Agent initialization
   - Full question processing workflow

3. **Interactive Testing**: Manual validation through CLI interface

## Environment Configuration

Required environment variables:
```
# Supabase configuration
SUPABASE_URL=<your-supabase-url>
SUPABASE_KEY=<your-supabase-anon-key>

# API Keys
OPENROUTER_API_KEY=<your-openrouter-api-key>
# Alternative: OPENAI_API_KEY

# Optional configuration
LOG_LEVEL=INFO  # Logging level (INFO, DEBUG, etc.)
DEBUG_MODE=false  # Enable debug mode
```

## Project Structure

Key files related to the agent implementation:

1. **Agent Core**:
   - `backend/python_modules/src/services/agent.py`: Main agent implementation

2. **Interface**:
   - `backend/python_modules/src/cli.py`: CLI implementation
   - `backend/python_modules/chatbot_cli.py`: CLI runner script

3. **Testing**:
   - `backend/python_modules/src/test_agent.py`: Agent tests
   - `backend/python_modules/test_agent_runner.py`: Test runner

4. **Configuration**:
   - `backend/python_modules/src/config/environment.py`: Environment configuration

5. **Database Access**:
   - `backend/python_modules/src/services/database.py`: Database service

## Implementation Notes

### Agent Features:
- **Conversation Memory**: The agent maintains a history of up to 10 previous exchanges to provide context
- **Error Handling**: Robust error management with informative error messages
- **Prompt Optimization**: Structured prompts with clear instructions for better responses
- **Metadata Integration**: Lesson metadata included in context for more relevant answers

### Performance Considerations:
- **Token Limits**: The maximum response is limited to 500 tokens to stay within API constraints
- **Temperature Setting**: Uses a temperature of 0.7 for balanced creativity and accuracy
- **History Management**: Limits conversation history to prevent context overflow

## Next Steps and Future Improvements

Potential enhancements for the agent implementation:

1. **Advanced RAG Techniques**:
   - Implement chunking for large transcriptions
   - Add vector embeddings for semantic search
   - Incorporate similarity scoring for better retrieval

2. **UI Integration**:
   - Connect agent with frontend interface
   - Implement real-time response streaming
   - Add feedback mechanisms for response quality

3. **Performance Optimization**:
   - Cache frequent queries and responses
   - Implement batching for multiple questions
   - Add support for asynchronous processing

4. **Extended Capabilities**:
   - Multi-document context (combining multiple lectures)
   - Image and video content understanding
   - Support for code execution in responses

## Troubleshooting

Common issues and solutions:

1. **API Connection Errors**:
   - Verify environment variables are correctly set
   - Check network connectivity to OpenRouter
   - Validate API key permissions

2. **Database Access Issues**:
   - Confirm Supabase connection parameters
   - Check RLS policies for anonymous access
   - Verify proper column names in queries

3. **Response Quality Issues**:
   - Review prompt structure for clarity
   - Consider using more advanced models
   - Ensure transcription quality is sufficient

## API Reference

### ChatbotAgent Class

**Constructor**:
```python
def __init__(self, api_key=None)
```
- `api_key`: Optional API key for OpenRouter. If not provided, uses the one from environment.

**Methods**:
```python
def create_prompt_with_context(self, question, transcription, lesson_info)
```
- Creates a prompt with context for the LLM
- Returns a list of message dictionaries

```python
def process_question(self, question, transcription, lesson_info, model="openai/gpt-4o")
```
- Processes a user question against a lecture transcription
- Returns the agent's response as a string

```python
def reset_conversation(self)
```
- Resets the conversation history

### CLI Functions

```python
def display_lessons(lessons)
```
- Displays the list of available lessons

```python
def select_lesson(lessons)
```
- Allows the user to select a lesson
- Returns the selected lesson ID or None if canceled

```python
def interactive_chat(agent, lesson_id)
```
- Starts an interactive chat session about a specific lesson 